{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":77759,"sourceType":"datasetVersion","datasetId":339}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:38:06.189418Z","iopub.execute_input":"2025-03-16T23:38:06.189821Z","iopub.status.idle":"2025-03-16T23:38:07.541757Z","shell.execute_reply.started":"2025-03-16T23:38:06.189782Z","shell.execute_reply":"2025-03-16T23:38:07.540419Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/movielens-20m-dataset/rating.csv\n/kaggle/input/movielens-20m-dataset/link.csv\n/kaggle/input/movielens-20m-dataset/genome_tags.csv\n/kaggle/input/movielens-20m-dataset/genome_scores.csv\n/kaggle/input/movielens-20m-dataset/tag.csv\n/kaggle/input/movielens-20m-dataset/movie.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"movies = pd.read_csv('/kaggle/input/movielens-20m-dataset/movie.csv')\nratings = pd.read_csv('/kaggle/input/movielens-20m-dataset/rating.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:38:07.543565Z","iopub.execute_input":"2025-03-16T23:38:07.544075Z","iopub.status.idle":"2025-03-16T23:38:31.428005Z","shell.execute_reply.started":"2025-03-16T23:38:07.544046Z","shell.execute_reply":"2025-03-16T23:38:31.426843Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Organize data and shrink","metadata":{}},{"cell_type":"code","source":"display(ratings)\ntotal_user = ratings['userId'].nunique()\ntotal_movie = ratings['movieId'].nunique()\nprint(f'The total number of unique users: {total_user}') # Total number of users is 138493\nprint(f'The total number of unique movies: {total_movie}') # Total number of users is 26744\n# Ｓince the total number of user and movie is too large for this exercise, I will shrink the data to save computational resources.\n# To do so, the filter would grab the 1000 movies with the most ratings, and the top 1000 users that rated these movies.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:39:36.508820Z","iopub.execute_input":"2025-03-16T23:39:36.509176Z","iopub.status.idle":"2025-03-16T23:39:36.872802Z","shell.execute_reply.started":"2025-03-16T23:39:36.509147Z","shell.execute_reply":"2025-03-16T23:39:36.871716Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"          userId  movieId  rating            timestamp\n0              1        2     3.5  2005-04-02 23:53:47\n1              1       29     3.5  2005-04-02 23:31:16\n2              1       32     3.5  2005-04-02 23:33:39\n3              1       47     3.5  2005-04-02 23:32:07\n4              1       50     3.5  2005-04-02 23:29:40\n...          ...      ...     ...                  ...\n20000258  138493    68954     4.5  2009-11-13 15:42:00\n20000259  138493    69526     4.5  2009-12-03 18:31:48\n20000260  138493    69644     3.0  2009-12-07 18:10:57\n20000261  138493    70286     5.0  2009-11-13 15:42:24\n20000262  138493    71619     2.5  2009-10-17 20:25:36\n\n[20000263 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:53:47</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>29</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:31:16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>32</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:33:39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:32:07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:29:40</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20000258</th>\n      <td>138493</td>\n      <td>68954</td>\n      <td>4.5</td>\n      <td>2009-11-13 15:42:00</td>\n    </tr>\n    <tr>\n      <th>20000259</th>\n      <td>138493</td>\n      <td>69526</td>\n      <td>4.5</td>\n      <td>2009-12-03 18:31:48</td>\n    </tr>\n    <tr>\n      <th>20000260</th>\n      <td>138493</td>\n      <td>69644</td>\n      <td>3.0</td>\n      <td>2009-12-07 18:10:57</td>\n    </tr>\n    <tr>\n      <th>20000261</th>\n      <td>138493</td>\n      <td>70286</td>\n      <td>5.0</td>\n      <td>2009-11-13 15:42:24</td>\n    </tr>\n    <tr>\n      <th>20000262</th>\n      <td>138493</td>\n      <td>71619</td>\n      <td>2.5</td>\n      <td>2009-10-17 20:25:36</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000263 rows × 4 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"The total number of unique users: 138493\nThe total number of unique movies: 26744\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Grab the 1000 movies with the most ratings\nratings['userId'] = ratings['userId'].astype(str)\nratings['movieId'] = ratings['movieId'].astype(str)\n\nmost_rated_movies = ratings['movieId'].value_counts().head(200).index  # get the 1000 most rated films\nmost_rated_movies = ratings[ratings['movieId'].isin(most_rated_movies)]  # get the 1000 most rated films\ndisplay(most_rated_movies)\nnum_movie = most_rated_movies['movieId'].nunique()\nprint(f'The total number of unique movies: {num_movie}') \n\n# # Grab the most frequent raters of the 1000 movies\nmost_frequent_raters = most_rated_movies['userId'].value_counts().head(200).index  # get the 1000 most rated films\nmost_frequent_raters = most_rated_movies[most_rated_movies['userId'].isin(most_frequent_raters)]  # get the 1000 most rated films\ndisplay(most_frequent_raters)\nnum_raters = most_frequent_raters['userId'].nunique()\nprint(f'The total number of raters: {num_raters}') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:39:36.880527Z","iopub.execute_input":"2025-03-16T23:39:36.880998Z","iopub.status.idle":"2025-03-16T23:39:56.072160Z","shell.execute_reply.started":"2025-03-16T23:39:36.880924Z","shell.execute_reply":"2025-03-16T23:39:56.071041Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"          userId movieId  rating            timestamp\n0              1       2     3.5  2005-04-02 23:53:47\n2              1      32     3.5  2005-04-02 23:33:39\n3              1      47     3.5  2005-04-02 23:32:07\n4              1      50     3.5  2005-04-02 23:29:40\n7              1     223     4.0  2005-04-02 23:46:13\n...          ...     ...     ...                  ...\n20000150  138493    6874     5.0  2009-10-17 19:08:23\n20000159  138493    7153     4.0  2009-11-16 16:50:20\n20000164  138493    7361     5.0  2009-10-17 19:26:47\n20000167  138493    7438     5.0  2009-10-17 19:08:26\n20000200  138493   33794     4.0  2009-12-07 18:16:51\n\n[5649025 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:53:47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>32</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:33:39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:32:07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>3.5</td>\n      <td>2005-04-02 23:29:40</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>223</td>\n      <td>4.0</td>\n      <td>2005-04-02 23:46:13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20000150</th>\n      <td>138493</td>\n      <td>6874</td>\n      <td>5.0</td>\n      <td>2009-10-17 19:08:23</td>\n    </tr>\n    <tr>\n      <th>20000159</th>\n      <td>138493</td>\n      <td>7153</td>\n      <td>4.0</td>\n      <td>2009-11-16 16:50:20</td>\n    </tr>\n    <tr>\n      <th>20000164</th>\n      <td>138493</td>\n      <td>7361</td>\n      <td>5.0</td>\n      <td>2009-10-17 19:26:47</td>\n    </tr>\n    <tr>\n      <th>20000167</th>\n      <td>138493</td>\n      <td>7438</td>\n      <td>5.0</td>\n      <td>2009-10-17 19:08:26</td>\n    </tr>\n    <tr>\n      <th>20000200</th>\n      <td>138493</td>\n      <td>33794</td>\n      <td>4.0</td>\n      <td>2009-12-07 18:16:51</td>\n    </tr>\n  </tbody>\n</table>\n<p>5649025 rows × 4 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"The total number of unique movies: 200\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          userId movieId  rating            timestamp\n106582       741       1     5.0  2007-10-16 21:51:03\n106583       741       2     3.0  2007-10-16 22:34:54\n106586       741       6     3.5  2007-10-16 22:04:06\n106588       741      10     4.0  2007-10-16 22:33:40\n106592       741      16     4.0  2007-11-10 18:48:00\n...          ...     ...     ...                  ...\n19962747  138208    7361     5.0  2004-04-02 22:27:50\n19962753  138208    7438     4.5  2004-05-19 03:45:25\n19962808  138208    8961     4.5  2004-11-15 05:17:55\n19962864  138208   33794     3.5  2005-06-26 05:32:25\n19963089  138208   58559     4.5  2008-07-20 23:36:38\n\n[38695 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106582</th>\n      <td>741</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>2007-10-16 21:51:03</td>\n    </tr>\n    <tr>\n      <th>106583</th>\n      <td>741</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>2007-10-16 22:34:54</td>\n    </tr>\n    <tr>\n      <th>106586</th>\n      <td>741</td>\n      <td>6</td>\n      <td>3.5</td>\n      <td>2007-10-16 22:04:06</td>\n    </tr>\n    <tr>\n      <th>106588</th>\n      <td>741</td>\n      <td>10</td>\n      <td>4.0</td>\n      <td>2007-10-16 22:33:40</td>\n    </tr>\n    <tr>\n      <th>106592</th>\n      <td>741</td>\n      <td>16</td>\n      <td>4.0</td>\n      <td>2007-11-10 18:48:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19962747</th>\n      <td>138208</td>\n      <td>7361</td>\n      <td>5.0</td>\n      <td>2004-04-02 22:27:50</td>\n    </tr>\n    <tr>\n      <th>19962753</th>\n      <td>138208</td>\n      <td>7438</td>\n      <td>4.5</td>\n      <td>2004-05-19 03:45:25</td>\n    </tr>\n    <tr>\n      <th>19962808</th>\n      <td>138208</td>\n      <td>8961</td>\n      <td>4.5</td>\n      <td>2004-11-15 05:17:55</td>\n    </tr>\n    <tr>\n      <th>19962864</th>\n      <td>138208</td>\n      <td>33794</td>\n      <td>3.5</td>\n      <td>2005-06-26 05:32:25</td>\n    </tr>\n    <tr>\n      <th>19963089</th>\n      <td>138208</td>\n      <td>58559</td>\n      <td>4.5</td>\n      <td>2008-07-20 23:36:38</td>\n    </tr>\n  </tbody>\n</table>\n<p>38695 rows × 4 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"The total number of raters: 200\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"shrink_df = most_frequent_raters\n# shrink_df is the shrinked dataframe, it holds the 1000 most rated movies and 1000 most frequent raters of those movies.\ndisplay(shrink_df)\n# now, we should rename user ID and movie ID to build are matrix, to do so, I will use a dictionary to map the old ID to the mew\nmap_user_ID = {}\nmap_movie_ID = {}\nnew_user_id = 0\nfor old_id in shrink_df['userId'].unique():\n    if old_id not in map_user_ID:\n        map_user_ID[old_id] = new_user_id\n        new_user_id += 1\n    else:\n        continue\n\nnew_movie_id = 0\nfor old_id in shrink_df['movieId'].unique():\n    if old_id not in map_movie_ID:\n        map_movie_ID[old_id] = new_movie_id\n        new_movie_id += 1\n    else:\n        continue\n        \nshrink_df['new_user_id'] =shrink_df['userId'].map(map_user_ID)\nshrink_df['new_movie_id'] =shrink_df['movieId'].map(map_movie_ID)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:39:56.073495Z","iopub.execute_input":"2025-03-16T23:39:56.073859Z","iopub.status.idle":"2025-03-16T23:39:56.113123Z","shell.execute_reply.started":"2025-03-16T23:39:56.073832Z","shell.execute_reply":"2025-03-16T23:39:56.111975Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"          userId movieId  rating            timestamp\n106582       741       1     5.0  2007-10-16 21:51:03\n106583       741       2     3.0  2007-10-16 22:34:54\n106586       741       6     3.5  2007-10-16 22:04:06\n106588       741      10     4.0  2007-10-16 22:33:40\n106592       741      16     4.0  2007-11-10 18:48:00\n...          ...     ...     ...                  ...\n19962747  138208    7361     5.0  2004-04-02 22:27:50\n19962753  138208    7438     4.5  2004-05-19 03:45:25\n19962808  138208    8961     4.5  2004-11-15 05:17:55\n19962864  138208   33794     3.5  2005-06-26 05:32:25\n19963089  138208   58559     4.5  2008-07-20 23:36:38\n\n[38695 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106582</th>\n      <td>741</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>2007-10-16 21:51:03</td>\n    </tr>\n    <tr>\n      <th>106583</th>\n      <td>741</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>2007-10-16 22:34:54</td>\n    </tr>\n    <tr>\n      <th>106586</th>\n      <td>741</td>\n      <td>6</td>\n      <td>3.5</td>\n      <td>2007-10-16 22:04:06</td>\n    </tr>\n    <tr>\n      <th>106588</th>\n      <td>741</td>\n      <td>10</td>\n      <td>4.0</td>\n      <td>2007-10-16 22:33:40</td>\n    </tr>\n    <tr>\n      <th>106592</th>\n      <td>741</td>\n      <td>16</td>\n      <td>4.0</td>\n      <td>2007-11-10 18:48:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19962747</th>\n      <td>138208</td>\n      <td>7361</td>\n      <td>5.0</td>\n      <td>2004-04-02 22:27:50</td>\n    </tr>\n    <tr>\n      <th>19962753</th>\n      <td>138208</td>\n      <td>7438</td>\n      <td>4.5</td>\n      <td>2004-05-19 03:45:25</td>\n    </tr>\n    <tr>\n      <th>19962808</th>\n      <td>138208</td>\n      <td>8961</td>\n      <td>4.5</td>\n      <td>2004-11-15 05:17:55</td>\n    </tr>\n    <tr>\n      <th>19962864</th>\n      <td>138208</td>\n      <td>33794</td>\n      <td>3.5</td>\n      <td>2005-06-26 05:32:25</td>\n    </tr>\n    <tr>\n      <th>19963089</th>\n      <td>138208</td>\n      <td>58559</td>\n      <td>4.5</td>\n      <td>2008-07-20 23:36:38</td>\n    </tr>\n  </tbody>\n</table>\n<p>38695 rows × 4 columns</p>\n</div>"},"metadata":{}},{"name":"stderr","text":"<ipython-input-5-ac2a27397215>:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  shrink_df['new_user_id'] =shrink_df['userId'].map(map_user_ID)\n<ipython-input-5-ac2a27397215>:24: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  shrink_df['new_movie_id'] =shrink_df['movieId'].map(map_movie_ID)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"display(shrink_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:39:56.114429Z","iopub.execute_input":"2025-03-16T23:39:56.114778Z","iopub.status.idle":"2025-03-16T23:39:56.128566Z","shell.execute_reply.started":"2025-03-16T23:39:56.114744Z","shell.execute_reply":"2025-03-16T23:39:56.127239Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"          userId movieId  rating            timestamp  new_user_id  \\\n106582       741       1     5.0  2007-10-16 21:51:03            0   \n106583       741       2     3.0  2007-10-16 22:34:54            0   \n106586       741       6     3.5  2007-10-16 22:04:06            0   \n106588       741      10     4.0  2007-10-16 22:33:40            0   \n106592       741      16     4.0  2007-11-10 18:48:00            0   \n...          ...     ...     ...                  ...          ...   \n19962747  138208    7361     5.0  2004-04-02 22:27:50          199   \n19962753  138208    7438     4.5  2004-05-19 03:45:25          199   \n19962808  138208    8961     4.5  2004-11-15 05:17:55          199   \n19962864  138208   33794     3.5  2005-06-26 05:32:25          199   \n19963089  138208   58559     4.5  2008-07-20 23:36:38          199   \n\n          new_movie_id  \n106582               0  \n106583               1  \n106586               2  \n106588               3  \n106592               4  \n...                ...  \n19962747           188  \n19962753           189  \n19962808           190  \n19962864           191  \n19963089           199  \n\n[38695 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>new_user_id</th>\n      <th>new_movie_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106582</th>\n      <td>741</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>2007-10-16 21:51:03</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106583</th>\n      <td>741</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>2007-10-16 22:34:54</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106586</th>\n      <td>741</td>\n      <td>6</td>\n      <td>3.5</td>\n      <td>2007-10-16 22:04:06</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>106588</th>\n      <td>741</td>\n      <td>10</td>\n      <td>4.0</td>\n      <td>2007-10-16 22:33:40</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>106592</th>\n      <td>741</td>\n      <td>16</td>\n      <td>4.0</td>\n      <td>2007-11-10 18:48:00</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19962747</th>\n      <td>138208</td>\n      <td>7361</td>\n      <td>5.0</td>\n      <td>2004-04-02 22:27:50</td>\n      <td>199</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>19962753</th>\n      <td>138208</td>\n      <td>7438</td>\n      <td>4.5</td>\n      <td>2004-05-19 03:45:25</td>\n      <td>199</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>19962808</th>\n      <td>138208</td>\n      <td>8961</td>\n      <td>4.5</td>\n      <td>2004-11-15 05:17:55</td>\n      <td>199</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>19962864</th>\n      <td>138208</td>\n      <td>33794</td>\n      <td>3.5</td>\n      <td>2005-06-26 05:32:25</td>\n      <td>199</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>19963089</th>\n      <td>138208</td>\n      <td>58559</td>\n      <td>4.5</td>\n      <td>2008-07-20 23:36:38</td>\n      <td>199</td>\n      <td>199</td>\n    </tr>\n  </tbody>\n</table>\n<p>38695 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# User-User CF\nThe first method is a user-user approach. Predict user_I's rating based on other users similar to user_I.","metadata":{}},{"cell_type":"code","source":"import numpy as np\ndef get_user_rating(user_id,main_df):\n    '''\n    This fxn filters the dataframe and return all movies rated by user_id\n    '''\n    df = main_df[main_df['userId'] == user_id]\n    \n    return df\n\ndef merge_two_users_df(user_one_df,user_two_df):\n    '''\n    This fxn merges does an inner join and the resulting datafram will contain movies that both user_one and user_two have rated.\n    '''\n\n    merged_df = pd.merge(user_one_df, user_two_df, on='movieId', how='inner')\n    \n    return merged_df\ndef calculate_similiarity(vector1,vector2):\n    '''\n    This fxn calculates the similarity between two users. \n    vector1 -> Contains all the ratings by user_I, but only with movies that user_J also rated.\n    vector2 -> Contains all the ratings by user_J, but only with movies that user_I also rated.\n\n    return\n    cosine_sim -> The similiarity of user_I, user_J when rating movies.\n    '''\n\n    dot_product = np.dot(vector1, vector2)\n    norm_vector1 = np.linalg.norm(vector1)\n    norm_vector2 = np.linalg.norm(vector2)\n    \n    cosine_sim = dot_product / (norm_vector1 * norm_vector2)\n    \n    # print(\"Cosine Similarity:\", cosine_sim)\n    return cosine_sim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:39:59.673090Z","iopub.execute_input":"2025-03-16T23:39:59.673489Z","iopub.status.idle":"2025-03-16T23:39:59.680750Z","shell.execute_reply.started":"2025-03-16T23:39:59.673457Z","shell.execute_reply":"2025-03-16T23:39:59.679432Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# loop through all users, calculate the cosine similiarity and store them in a 2D list.\nnum_rows = shrink_df['userId'].nunique()\nnum_cols = shrink_df['userId'].nunique()\n\nrows = []\ncount = 0\nfor user_1 in shrink_df['userId'].unique():\n    row = []\n    # if count%(shrink_df['movieId'].nunique()/10) == 0:\n    #     print(map_user_ID[user_1])\n        \n    for user_2 in shrink_df['userId'].unique():\n            \n        user_rating_1 = get_user_rating(user_id = user_1,main_df = shrink_df)\n        user_rating_2 = get_user_rating(user_id = user_2,main_df = shrink_df)\n\n        merged_df = merge_two_users_df(user_one_df = user_rating_1,user_two_df = user_rating_2)\n        \n        vector_1 = merged_df['rating_x']\n        vector_2 = merged_df['rating_y']\n\n        weight = calculate_similiarity(vector_1,vector_2)\n\n        row.append(weight)\n    count += 1\n    rows.append(row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:40:03.957009Z","iopub.execute_input":"2025-03-16T23:40:03.957384Z","iopub.status.idle":"2025-03-16T23:48:32.849438Z","shell.execute_reply.started":"2025-03-16T23:40:03.957355Z","shell.execute_reply":"2025-03-16T23:48:32.848398Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"weight_matrix_arr = np.array(rows)\nweight_matrix = rows\n# weights_matrix is a symmetric matrix that stores the similiarity of two users. EX: W[i][j] is the similiarity of user i and user j.\nprint(f'The shape of the weight matrix is {weight_matrix_arr.shape}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:48:53.556738Z","iopub.execute_input":"2025-03-16T23:48:53.557125Z","iopub.status.idle":"2025-03-16T23:48:53.566065Z","shell.execute_reply.started":"2025-03-16T23:48:53.557096Z","shell.execute_reply":"2025-03-16T23:48:53.564933Z"}},"outputs":[{"name":"stdout","text":"The shape of the weight matrix is (200, 200)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def get_largest_indices(arr, n):\n    '''\n    This fxn returns the indices of the largest n values in a np array\n    '''\n    return np.argpartition(arr, -n)[-n:]\n    \ndef user_average_rating(user_id,main_df):\n    '''\n    This fxn returns the average ratings of a user in main_df\n    '''\n    avg =  main_df[main_df['new_user_id'] == user_id]['rating'].mean()\n\n    return avg\n\ndef user_rating_movie(user_id,movie_id,main_df):\n    '''\n    This fxn gives the rating of user_i to movie_j\n    '''\n\n    rating = main_df[(main_df['new_user_id'] == user_id) & (main_df['new_movie_id'] == movie_id)]['rating'].values[0]\n\n    return rating\n\n\ndef predict_score(user_i_id, movie_m_id, main_df, weight_matrix):\n\n    user_i_avg = user_average_rating(user_id = user_i_id,main_df = main_df)\n\n    closest_K_indices = get_largest_indices(weight_matrix[user_i_id], n=26) # find the closest K users to calculate score, closest K will be the largest similiarity in weight_matrix\n    \n    numerator_lst = []\n    denominator_lst = []\n\n    for user_j in closest_K_indices[1:]: \n\n        try:\n            \n            user_j_avg = user_average_rating(user_id = user_j,main_df = main_df)\n            user_j_rating = user_rating_movie(user_id = user_j,movie_id = movie_m_id,main_df = main_df)\n        \n        except:          \n\n            continue\n            \n        numerator_lst.append(weight_matrix[user_i_id][user_j] * (user_j_rating - user_j_avg))\n        denominator_lst.append(abs(weight_matrix[user_i_id][user_j]))\n\n    numerator =  sum(numerator_lst) # sum {weights * ( user j rating of movie m - average rating of user j)}\n    denominator = sum(denominator_lst) # absolute weights of the closest K users to calculate score\n\n    score = (numerator / denominator) + user_i_avg\n    # print(f'Predicted score: {score}')\n    \n    return score\n\ndef MSE(predict,ground_truth):\n\n    predict_arr = np.array(predict)\n    ground_truth_arr = np.array(ground_truth)\n    MSE = np.mean((ground_truth_arr-predict_arr)**2)\n    \n    return MSE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:48:54.893640Z","iopub.execute_input":"2025-03-16T23:48:54.894006Z","iopub.status.idle":"2025-03-16T23:48:54.903878Z","shell.execute_reply.started":"2025-03-16T23:48:54.893966Z","shell.execute_reply":"2025-03-16T23:48:54.902797Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"predict_lst_user = []\nground_truth_lst_user = []\n\nfor user_i in shrink_df.new_user_id.unique():\n    print(user_i)\n    for movie_m in shrink_df.new_movie_id.unique():\n\n        try:\n            ground_truth = shrink_df[(shrink_df.new_user_id == user_i) & (shrink_df.new_movie_id == movie_m)]['rating'].values[0]\n            score = predict_score(user_i_id = user_i, movie_m_id = movie_m, main_df = shrink_df, weight_matrix = weight_matrix_arr)\n            predict_lst_user.append(score)\n            ground_truth_lst_user.append(ground_truth)\n        except:\n            # print(f'User {user_i} did not rate movie {movie_m}. Ground truth does not exist.')\n            continue\n        # break\n    # break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T23:48:58.656522Z","iopub.execute_input":"2025-03-16T23:48:58.656893Z","iopub.status.idle":"2025-03-17T00:07:23.832969Z","shell.execute_reply.started":"2025-03-16T23:48:58.656867Z","shell.execute_reply":"2025-03-17T00:07:23.831757Z"}},"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Item-Item CF\nUse the similiarity of items to predict the ratings of a user. How one user i would rate item to predict what he how he would rate another item that is similar. In application, this method shuold be more accurate","metadata":{}},{"cell_type":"code","source":"#We still have to calculate the similiarity but this time it's the similiarity of two items. The same fxn can be used here. \ndef Item_df(item_id,main_df):\n    '''\n    This fxn filters the main_df and return only users that rated item_I\n    '''\n\n    item_df = main_df[main_df['movieId'] == item_id]\n\n    return item_df\n\ndef merge_item_df(item_i_df,item_j_df):\n    '''\n    This fxn inner joins two item df and returns the intersect of both items.\n    The return df should include users that rated both Item_I and Item_J\n    '''\n    \n    return pd.merge(item_i_df, item_j_df, on='userId', how='inner') \n\ndef calculate_similiarity(vector1,vector2):\n    '''\n    This fxn calculates the similarity between two users. \n    vector1 -> Contains all the ratings of Item_I, but only with movies that Item_J also rated.\n    vector2 -> Contains all the ratings by Item_J, but only with movies that Item_I also rated.\n\n    return\n    cosine_sim -> The similiarity of user_I, user_J when rating movies.\n    '''\n\n    dot_product = np.dot(vector1, vector2)\n    norm_vector1 = np.linalg.norm(vector1)\n    norm_vector2 = np.linalg.norm(vector2)\n    \n    cosine_sim = dot_product / (norm_vector1 * norm_vector2)\n    \n    # print(\"Cosine Similarity:\", cosine_sim)\n    return cosine_sim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T00:07:45.910396Z","iopub.execute_input":"2025-03-17T00:07:45.910797Z","iopub.status.idle":"2025-03-17T00:07:45.917121Z","shell.execute_reply.started":"2025-03-17T00:07:45.910766Z","shell.execute_reply":"2025-03-17T00:07:45.916085Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"rows = []\ncount = 0\nfor item_i in shrink_df['movieId'].unique():\n    row = []\n    # if count%(shrink_df['movieId'].nunique()/10) == 0:\n    #     print(map_movie_ID[item_i]/10)\n        \n    for item_j in shrink_df['movieId'].unique():\n            \n        item_rating_i = Item_df(item_id = item_i,main_df = shrink_df)\n        item_rating_j = Item_df(item_id = item_j,main_df = shrink_df)\n\n        merge_item_df = pd.merge(item_rating_i, item_rating_j, on='userId', how='inner') \n        \n        vector_1 = merge_item_df['rating_x']\n        vector_2 = merge_item_df['rating_y']\n\n        weight = calculate_similiarity(vector_1,vector_2)\n\n        row.append(weight)\n        # break\n    # break\n    count += 1\n    rows.append(row)\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T00:07:47.955259Z","iopub.execute_input":"2025-03-17T00:07:47.955626Z","iopub.status.idle":"2025-03-17T00:16:28.605380Z","shell.execute_reply.started":"2025-03-17T00:07:47.955577Z","shell.execute_reply":"2025-03-17T00:16:28.604337Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"weight_matrix_arr = np.array(rows)\nweight_matrix = rows\n# weight_matrix is a symmetric matrix that stores the similiarity of two items based on how two items were rated by the same users. EX: W[i][j] is the similiarity of item i and item j.\nprint(f'The shape of the weight matrix is {weight_matrix_arr.shape}')\n# weight_matrix_arr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T00:16:33.694353Z","iopub.execute_input":"2025-03-17T00:16:33.694744Z","iopub.status.idle":"2025-03-17T00:16:33.703474Z","shell.execute_reply.started":"2025-03-17T00:16:33.694712Z","shell.execute_reply":"2025-03-17T00:16:33.702417Z"}},"outputs":[{"name":"stdout","text":"The shape of the weight matrix is (200, 200)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def get_largest_indices(arr, n):\n    '''\n    This fxn returns the indices of the largest n values in a np array\n    '''\n    return np.argpartition(arr, -n)[-n:]\n    \ndef items_average_rating(movie_id,main_df):\n    '''\n    This fxn returns the average ratings of a user in main_df\n    '''\n    avg =  main_df[main_df['new_movie_id'] == movie_id]['rating'].mean()\n\n    return avg\n\ndef user_rating_movie(user_id,movie_id,main_df):\n    '''\n    This fxn gives the rating of user_i to movie_j\n    '''\n\n    rating = main_df[(main_df['new_user_id'] == user_id) & (main_df['new_movie_id'] == movie_id)]['rating'].values[0]\n\n    return rating\n\n\ndef predict_score(user_i_id, movie_m_id, main_df, weight_matrix):\n\n    movie_m_avg = items_average_rating(movie_id = movie_m_id,main_df = main_df)\n\n    closest_K_indices = get_largest_indices(weight_matrix[movie_m_id], n=26) # find the closest K users to calculate score, closest K will be the largest similiarity in weight_matrix\n    \n    numerator_lst = []\n    denominator_lst = []\n\n    for movie_j in closest_K_indices[1:]: \n\n        try:\n            \n            movie_j_avg = items_average_rating(movie_id = movie_j,main_df = main_df)\n            movie_j_rating = user_rating_movie(user_id = user_i_id,movie_id = movie_j,main_df = main_df)\n        \n        except:          \n\n            continue\n            \n        numerator_lst.append(weight_matrix[movie_m_id][movie_j] * (movie_j_rating - movie_j_avg))\n        denominator_lst.append(abs(weight_matrix[movie_m_id][movie_j]))\n\n    numerator =  sum(numerator_lst) # sum {weights * ( user j rating of movie m - average rating of user j)}\n    denominator = sum(denominator_lst) # absolute weights of the closest K users to calculate score\n\n    score = (numerator / denominator) + movie_m_avg\n    # print(f'Predicted score: {score}')\n    \n    return score\n\ndef MSE(predict,ground_truth):\n\n    predict_arr = np.array(predict)\n    ground_truth_arr = np.array(ground_truth)\n    MSE = np.mean((ground_truth_arr-predict_arr)**2)\n    \n    return MSE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T00:16:37.458479Z","iopub.execute_input":"2025-03-17T00:16:37.458861Z","iopub.status.idle":"2025-03-17T00:16:37.468261Z","shell.execute_reply.started":"2025-03-17T00:16:37.458830Z","shell.execute_reply":"2025-03-17T00:16:37.467216Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"predict_lst_item = []\nground_truth_lst_item = []\n\nfor movie_m in shrink_df.new_movie_id.unique():\n    print(movie_m)\n    for user_i in shrink_df.new_user_id.unique():\n\n        try:\n            ground_truth = shrink_df[(shrink_df.new_user_id == user_i) & (shrink_df.new_movie_id == movie_m)]['rating'].values[0]\n            score = predict_score(user_i_id = user_i, movie_m_id = movie_m, main_df = shrink_df, weight_matrix = weight_matrix_arr)\n            predict_lst_item.append(score)\n            ground_truth_lst_item.append(ground_truth)\n        except:\n            # print(f'User {user_i} did not rate movie {movie_m}. Ground truth does not exist.')\n            continue\n        # break\n    # break\n# MSE = MSE(predict = predict_lst,ground_truth = ground_truth_lst)\n# print(f'The final MSE:  {MSE}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T00:16:40.964129Z","iopub.execute_input":"2025-03-17T00:16:40.964477Z","iopub.status.idle":"2025-03-17T00:36:10.537253Z","shell.execute_reply.started":"2025-03-17T00:16:40.964451Z","shell.execute_reply":"2025-03-17T00:36:10.536080Z"}},"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"user_mse = MSE(predict = predict_lst_user,ground_truth = ground_truth_lst_user)\nitem_mse = MSE(predict = predict_lst_item,ground_truth = ground_truth_lst_item)\nprint(f'The final MSE using user-user:  {user_mse}')\nprint(f'The final MSE using item-item:  {item_mse}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T00:37:01.739320Z","iopub.execute_input":"2025-03-17T00:37:01.739730Z","iopub.status.idle":"2025-03-17T00:37:01.799391Z","shell.execute_reply.started":"2025-03-17T00:37:01.739699Z","shell.execute_reply":"2025-03-17T00:37:01.798365Z"}},"outputs":[{"name":"stdout","text":"The final MSE using user-user:  0.46189767055778486\nThe final MSE using item-item:  0.42629396665770486\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# SUMMARY\nCollaborative filtering is a recommending technique that is user specific. It can be split into a User- User approach vs a Item-item approach.\n## User-user\nIn this approach, the concept is to use the similiarity between users to predict ratings of a specific item. Meaning: \"These users are similar to you in ratings, so you would probabbly like this new item they already rated highly.\"\nTo do so. the first step it to calculate the similiarity of two users based on the items they have both rated and store these as weights in a 2D matrix. To predict the score that user i will rate item j, we add the adverage rating of user i and the weighted average of how other users similar to user i(KNN) deviates from their average score, when they rate item j.\n\n## Item-item \nThis approach is not as intuitive. The concept is to use the similiarity of items to make recommendations. To do so. the first step it to calculate the similiarity of two items based on users that have rated both items. \nTo predict the score that user i will rate item j, we add the average rating of item j to the weighted average of the deviation of the ratings when other items similar to item j is being rated.","metadata":{}}]}